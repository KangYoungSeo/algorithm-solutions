{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "21456330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss : 17.328679513998633 \n",
      "\n",
      "loss : 18.92078229137859 \n",
      "\n",
      "loss : 19.864995681401467 \n",
      "\n",
      "loss : 20.391977810605148 \n",
      "\n",
      "loss : 20.660431508390484 \n",
      "\n",
      "loss : 20.771914932319447 \n",
      "\n",
      "loss : 20.789644238954654 \n",
      "\n",
      "loss : 20.752467133229132 \n",
      "\n",
      "loss : 20.68406699132464 \n",
      "\n",
      "loss : 20.598780735612596 \n",
      "\n",
      "loss : 20.50521523806163 \n",
      "\n",
      "loss : 20.408477863711823 \n",
      "\n",
      "loss : 20.311546561700005 \n",
      "\n",
      "loss : 20.216109276919163 \n",
      "\n",
      "loss : 20.123077230178737 \n",
      "\n",
      "loss : 20.032898179983903 \n",
      "\n",
      "loss : 19.945747164772005 \n",
      "\n",
      "loss : 19.86164226234205 \n",
      "\n",
      "loss : 19.78051449592721 \n",
      "\n",
      "loss : 19.702249728361043 \n",
      "\n",
      "loss : 19.626713470131293 \n",
      "\n",
      "loss : 19.553765291708864 \n",
      "\n",
      "loss : 19.483266936490587 \n",
      "\n",
      "loss : 19.415086641422818 \n",
      "\n",
      "loss : 19.349101198241595 \n",
      "\n",
      "loss : 19.285196690891297 \n",
      "\n",
      "loss : 19.223268478221694 \n",
      "\n",
      "loss : 19.163220766238837 \n",
      "\n",
      "loss : 19.104965976319843 \n",
      "\n",
      "loss : 19.04842403137054 \n",
      "\n",
      "loss : 18.993521630331422 \n",
      "\n",
      "loss : 18.940191550079593 \n",
      "\n",
      "loss : 18.888371994851294 \n",
      "\n",
      "loss : 18.83800600203108 \n",
      "\n",
      "loss : 18.78904090656432 \n",
      "\n",
      "loss : 18.741427862526834 \n",
      "\n",
      "loss : 18.695121418403083 \n",
      "\n",
      "loss : 18.650079141688856 \n",
      "\n",
      "loss : 18.60626128811682 \n",
      "\n",
      "loss : 18.56363051084194 \n",
      "\n",
      "loss : 18.522151605156704 \n",
      "\n",
      "loss : 18.481791284636813 \n",
      "\n",
      "loss : 18.442517984987912 \n",
      "\n",
      "loss : 18.40430169223917 \n",
      "\n",
      "loss : 18.367113792290585 \n",
      "\n",
      "loss : 18.330926939158616 \n",
      "\n",
      "loss : 18.295714939573465 \n",
      "\n",
      "loss : 18.26145265186091 \n",
      "\n",
      "loss : 18.228115897291683 \n",
      "\n",
      "loss : 18.195681382304226 \n",
      "\n",
      "loss : 18.164126630204052 \n",
      "\n",
      "loss : 18.13342992111741 \n",
      "\n",
      "loss : 18.103570239130523 \n",
      "\n",
      "loss : 18.074527225680704 \n",
      "\n",
      "loss : 18.046281138384618 \n",
      "\n",
      "loss : 18.01881281459264 \n",
      "\n",
      "loss : 17.992103639049773 \n",
      "\n",
      "loss : 17.9661355151233 \n",
      "\n",
      "loss : 17.9408908391273 \n",
      "\n",
      "loss : 17.916352477335185 \n",
      "\n",
      "loss : 17.892503745324934 \n",
      "\n",
      "loss : 17.869328389348272 \n",
      "\n",
      "loss : 17.84681056945578 \n",
      "\n",
      "loss : 17.824934844145517 \n",
      "\n",
      "loss : 17.803686156333605 \n",
      "\n",
      "loss : 17.783049820472502 \n",
      "\n",
      "loss : 17.763011510665823 \n",
      "\n",
      "loss : 17.7435572496494 \n",
      "\n",
      "loss : 17.724673398525983 \n",
      "\n",
      "loss : 17.70634664715633 \n",
      "\n",
      "loss : 17.688564005123155 \n",
      "\n",
      "loss : 17.671312793195803 \n",
      "\n",
      "loss : 17.654580635233852 \n",
      "\n",
      "loss : 17.638355450476546 \n",
      "\n",
      "loss : 17.622625446172496 \n",
      "\n",
      "loss : 17.60737911051071 \n",
      "\n",
      "loss : 17.59260520581972 \n",
      "\n",
      "loss : 17.57829276200631 \n",
      "\n",
      "loss : 17.564431070209757 \n",
      "\n",
      "loss : 17.551009676650885 \n",
      "\n",
      "loss : 17.53801837665858 \n",
      "\n",
      "loss : 17.525447208858804 \n",
      "\n",
      "loss : 17.5132864495137 \n",
      "\n",
      "loss : 17.501526607000084 \n",
      "\n",
      "loss : 17.490158416418367 \n",
      "\n",
      "loss : 17.479172834324395 \n",
      "\n",
      "loss : 17.468561033577757 \n",
      "\n",
      "loss : 17.458314398301248 \n",
      "\n",
      "loss : 17.448424518946883 \n",
      "\n",
      "loss : 17.43888318746463 \n",
      "\n",
      "loss : 17.429682392570662 \n",
      "\n",
      "loss : 17.420814315112217 \n",
      "\n",
      "loss : 17.412271323526856 \n",
      "\n",
      "loss : 17.404045969393884 \n",
      "\n",
      "loss : 17.396130983076283 \n",
      "\n",
      "loss : 17.388519269451535 \n",
      "\n",
      "loss : 17.381203903729784 \n",
      "\n",
      "loss : 17.37417812735834 \n",
      "\n",
      "loss : 17.367435344010957 \n",
      "\n",
      "loss : 17.360969115661145 \n",
      "\n",
      "w = [-2.09654683 -0.5129636   3.59533132  2.10489979]\n",
      "\n",
      "x_tom = [1.  1.  0.1 0.5]\n",
      "y_tom_hat : 0.23191537041980337\n",
      "\n",
      "he is opposition party\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "N = 9 # the number of training data\n",
    "X = np.array([[1.0,1.0,0.85,0.76],\n",
    "              [1.0,1.0,0.0,0.24],\n",
    "              [1.0,0.0,0.625,0.84],\n",
    "              [1.0,0.0,0.45,0.96],\n",
    "              [1.0,1.0,0.225,0.46],\n",
    "              [1.0,0.0,0.25,0.7],\n",
    "              [1.0,1.0,0.7,0.44],\n",
    "              [1.0,0.0,0.3,0.4],\n",
    "              [1.0,0.0,0.125,0.66]])\n",
    "\n",
    "y = np.array([1,0,1,1,0,0,1,0,1])\n",
    "w = np.array([0,0,0,0])\n",
    "learning_rate = 0.1\n",
    "iteration = 100 # 100\n",
    "\n",
    "# sigmoid function\n",
    "def sigmoid( w, X_new):\n",
    "    Z = np.matmul(X_new,w)\n",
    "    return (1.0 / (1 + np.exp(-Z))) \n",
    "\n",
    "# compute binary cross entropy loss and print\n",
    "def get_cost( y, y_hat):\n",
    "    return - np.sum(np.dot(y.T,np.log(1-y_hat)+ np.dot((1-y).T,np.log(1-y_hat))))\n",
    "\n",
    "\n",
    "# update w using X, y, y_hat\n",
    "def update_w (w , y , y_hat, X_new, rate,n):\n",
    "   \n",
    "    dw = np.dot((y_hat - y), X_new)\n",
    "    w = w - rate * dw\n",
    "\n",
    "    return w\n",
    "\n",
    "\n",
    "# learning by gradient descent\n",
    "for i in range(iteration):\n",
    "    # compute y_hat from X and w\n",
    "    y_hat = sigmoid( w , X)\n",
    "\n",
    "    # get binary cross entropy loss and print\n",
    "    loss = get_cost(y,y_hat)\n",
    "    print(f'loss : {loss} \\n')\n",
    "\n",
    "    # get update w\n",
    "    w = update_w(w,y,y_hat,X,0.1,N)\n",
    "    #print(f'y : {y}  y_hat : {y_hat} \\n')\n",
    "    \n",
    "# the learned model parameter\n",
    "print(f'w = {w}\\n')\n",
    "\n",
    "# new data x_tom for tom = (sex=M, age=24, income=2500)\n",
    "x_tom = np.array([1,1,0.1,0.5])\n",
    "print(f'x_tom = {x_tom}')\n",
    "\n",
    "# compute y_tom_hat and print\n",
    "y_tom_hat = sigmoid(w,x_tom)\n",
    "print(f'y_tom_hat : {y_tom_hat}\\n')\n",
    "\n",
    "# print classification result\n",
    "if(y_tom_hat > 0.5) :\n",
    "    print('he is ruling party\\n')\n",
    "elif(y_tom_hat <= 0.5) :\n",
    "    print('he is opposition party\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88aa748",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "4cbf50f5b82fbbe84ea79711ebb84cd63cd1cdfbaa43c2ca510110a84c702e60"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
